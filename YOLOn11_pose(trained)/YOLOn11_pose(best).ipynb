{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 이미지로 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "처리된 총 프레임 수: 216\n",
      "✅ 결과 동영상이 'E:\\Desktop\\AI_learning\\Project_2_Object_detection\\core\\YOLOn11_pose(trained)\\YzW8PZ8PLpc.mp4'로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "# 1. 모델 불러오기\n",
    "model_path = r\"E:\\Desktop\\AI_learning\\Project_2_Object_detection\\core\\YOLOn11_pose(trained)\\train3\\weights\\best.pt\"\n",
    "model = YOLO(model_path)\n",
    "\n",
    "# 2. 동영상 파일 경로 및 출력 설정\n",
    "filename = \"YzW8PZ8PLpc\"\n",
    "input_video_path = f\"E:\\Desktop\\AI_learning\\Project_2_Object_detection\\core\\YOLOn11_pose(trained)\\{filename}.webm\"\n",
    "output_video_path = f\"E:\\Desktop\\AI_learning\\Project_2_Object_detection\\core\\YOLOn11_pose(trained)\\{filename}.mp4\"\n",
    "\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "# 동영상 정보 추출 (프레임 너비, 높이, FPS)\n",
    "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps    = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# 3. VideoWriter 설정 (MP4로 저장)\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")  # 코덱 설정\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "frame_count = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        # 더 이상 프레임이 없으면 중단\n",
    "        break\n",
    "\n",
    "    # 4. 모델 예측 (프레임 단위) - YOLO 기본 시각화 사용\n",
    "    results = model.predict(source=frame, verbose=False)\n",
    "\n",
    "    # 5. YOLO가 자동으로 그려준 결과 이미지 가져오기\n",
    "    result_img = results[0].plot()  # 바운딩 박스, 키포인트 자동 표시됨\n",
    "\n",
    "    # 6. 시각화된 프레임을 VideoWriter에 저장\n",
    "    out.write(result_img)\n",
    "    frame_count += 1\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "print(f\"처리된 총 프레임 수: {frame_count}\")\n",
    "print(f\"✅ 결과 동영상이 '{output_video_path}'로 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 영상으로 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "처리된 총 프레임 수: 909\n",
      "결과 동영상이 'E:\\Desktop\\AI_learning\\Project_2_Object_detection\\core\\YOLOn11_pose(trained)\\KakaoTalk_20250320_170351556-2.mp4'로 저장되었습니다.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "# 1. 모델 불러오기\n",
    "model_path = r\"E:\\Desktop\\AI_learning\\Project_2_Object_detection\\core\\YOLOn11_pose(trained)\\train3\\weights\\best.pt\"\n",
    "model = YOLO(model_path)\n",
    "\n",
    "# 2. 동영상 파일 경로 및 출력 설정\n",
    "filename = \"KakaoTalk_20250320_170345854\"\n",
    "input_video_path = f\"E:\\Desktop\\AI_learning\\Project_2_Object_detection\\core\\YOLOn11_pose(trained)\\{filename}.mp4\"\n",
    "output_video_path = f\"E:\\Desktop\\AI_learning\\Project_2_Object_detection\\core\\YOLOn11_pose(trained)\\{filename}-2.mp4\"\n",
    "\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "\n",
    "# 동영상 정보 추출 (프레임 너비, 높이, FPS)\n",
    "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps    = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# 3. VideoWriter 설정 (MP4로 저장)\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")  # 코덱 설정\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "frame_count = 0\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        # 더 이상 프레임이 없으면 중단\n",
    "        break\n",
    "\n",
    "    # 4. 모델 예측 (프레임 단위)\n",
    "    results = model.predict(source=frame, verbose=False)\n",
    "\n",
    "    # 5. 예측 결과를 프레임에 시각화\n",
    "    for result in results:\n",
    "        for i, (box, keypoints) in enumerate(zip(result.boxes.xyxy, result.keypoints.xy)):\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "\n",
    "            # 클래스 인덱스와 라벨\n",
    "            class_id = int(result.boxes.cls[i])\n",
    "            label = model.names.get(class_id, str(class_id))\n",
    "\n",
    "            # 바운딩 박스\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 0), 2)\n",
    "\n",
    "            # 라벨 텍스트\n",
    "            label_x = x1 + 5\n",
    "            label_y = y1 + 20\n",
    "            cv2.putText(frame, label, (label_x, label_y),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "\n",
    "            # 키포인트\n",
    "            for x, y in keypoints:\n",
    "                if x > 0 and y > 0:  # 유효한 좌표만 표시\n",
    "                    cv2.circle(frame, (int(x), int(y)), 5, (0, 255, 0), -1)\n",
    "\n",
    "    # 6. 시각화가 끝난 프레임을 VideoWriter에 저장\n",
    "    out.write(frame)\n",
    "    frame_count += 1\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "\n",
    "print(f\"처리된 총 프레임 수: {frame_count}\")\n",
    "print(f\"결과 동영상이 '{output_video_path}'로 저장되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

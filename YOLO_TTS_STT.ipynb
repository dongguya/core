{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pygame\n",
      "  Downloading pygame-2.6.1-cp39-cp39-win_amd64.whl.metadata (13 kB)\n",
      "Downloading pygame-2.6.1-cp39-cp39-win_amd64.whl (10.6 MB)\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ------------------------ --------------- 6.6/10.6 MB 31.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.6/10.6 MB 25.5 MB/s eta 0:00:00\n",
      "Installing collected packages: pygame\n",
      "Successfully installed pygame-2.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import serial\n",
    "import serial.tools.list_ports\n",
    "import random\n",
    "from elevenlabs import ElevenLabs\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import tempfile\n",
    "import pygame\n",
    "\n",
    "# API Key 직접 설정\n",
    "load_dotenv()\n",
    "ELEVENLABS_API_KEY = os.getenv(\"ELEVENLABS_API_KEY\")\n",
    "VOICE_ID = \"uyVNoMrnUku1dZyVEXwD\"\n",
    "\n",
    "# Init client\n",
    "client_tts = ElevenLabs(api_key=ELEVENLABS_API_KEY)\n",
    "\n",
    "# Device setting\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = torch.jit.load(\"dongguya.torchscript\", map_location=device)\n",
    "model.eval()\n",
    "\n",
    "# --------------------------------------\n",
    "# 🔊 TTS: speak 함수 (실시간 재생, pygame 사용)\n",
    "# --------------------------------------\n",
    "def speak(text):\n",
    "    audio_stream = client_tts.text_to_speech.convert(\n",
    "        text=text,\n",
    "        voice_id=VOICE_ID,\n",
    "        model_id=\"eleven_multilingual_v2\",\n",
    "        voice_settings={  \n",
    "        \"stability\": 0.2,\n",
    "        \"similarity_boost\": 0.8,\n",
    "        \"style\": 0.9\n",
    "        }\n",
    "\n",
    "    )\n",
    "    audio_bytes = b\"\".join(chunk for chunk in audio_stream)\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\") as temp_audio:\n",
    "        temp_audio.write(audio_bytes)\n",
    "        temp_audio_path = temp_audio.name\n",
    "\n",
    "    pygame.mixer.init()\n",
    "    pygame.mixer.music.load(temp_audio_path)\n",
    "    pygame.mixer.music.play()\n",
    "    while pygame.mixer.music.get_busy():\n",
    "        pygame.time.Clock().tick(10)\n",
    "    pygame.mixer.quit()\n",
    "\n",
    "    os.remove(temp_audio_path)\n",
    "\n",
    "# --------------------------------------\n",
    "# 📦 YOLO 관련 전처리 & 후처리 함수\n",
    "# --------------------------------------\n",
    "def preprocess_frame(frame, img_size=640):\n",
    "    img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (img_size, img_size))\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "    tensor = torch.from_numpy(img).permute(2, 0, 1).unsqueeze(0)\n",
    "    return tensor.to(device)\n",
    "\n",
    "def box_iou(box1, box2):\n",
    "    x1 = torch.max(box1[:, None, 0], box2[:, 0])\n",
    "    y1 = torch.max(box1[:, None, 1], box2[:, 1])\n",
    "    x2 = torch.min(box1[:, None, 2], box2[:, 2])\n",
    "    y2 = torch.min(box1[:, None, 3], box2[:, 3])\n",
    "    inter = (x2 - x1).clamp(0) * (y2 - y1).clamp(0)\n",
    "    area1 = (box1[:, 2] - box1[:, 0]) * (box1[:, 3] - box1[:, 1])\n",
    "    area2 = (box2[:, 2] - box2[:, 0]) * (box2[:, 3] - box2[:, 1])\n",
    "    union = area1[:, None] + area2 - inter\n",
    "    return inter / union\n",
    "\n",
    "def simple_nms(boxes, scores, iou_threshold=0.5):\n",
    "    idxs = scores.argsort(descending=True)\n",
    "    keep = []\n",
    "    while idxs.numel() > 0:\n",
    "        current = idxs[0].item()\n",
    "        keep.append(current)\n",
    "        if idxs.numel() == 1:\n",
    "            break\n",
    "        ious = box_iou(boxes[current].unsqueeze(0), boxes[idxs[1:]])[0]\n",
    "        idxs = idxs[1:][ious < iou_threshold]\n",
    "    return keep\n",
    "\n",
    "def postprocess_yolo(preds, orig_shape, conf_threshold=0.5, iou_threshold=0.5, img_size=640):\n",
    "    preds = preds.permute(0, 2, 1)[0]\n",
    "    cls_confidences = preds[:, 4:7]\n",
    "    cls_conf, cls_ids = cls_confidences.max(dim=1)\n",
    "    mask = cls_conf > conf_threshold\n",
    "    if not mask.any():\n",
    "        return []\n",
    "    boxes = preds[mask, :4]\n",
    "    scores = cls_conf[mask]\n",
    "    classes = cls_ids[mask]\n",
    "    keypoints = preds[mask, 7:].reshape(-1, 24, 3)\n",
    "    xy = boxes[:, :2] - boxes[:, 2:] / 2\n",
    "    wh = boxes[:, :2] + boxes[:, 2:]\n",
    "    boxes_xyxy = torch.cat((xy, wh), dim=1)\n",
    "    keep = simple_nms(boxes_xyxy, scores, iou_threshold)\n",
    "    boxes_xyxy = boxes_xyxy[keep]\n",
    "    scores = scores[keep]\n",
    "    classes = classes[keep]\n",
    "    keypoints = keypoints[keep]\n",
    "    orig_h, orig_w = orig_shape\n",
    "    scale = torch.tensor([orig_w / img_size, orig_h / img_size, orig_w / img_size, orig_h / img_size], device=boxes_xyxy.device)\n",
    "    boxes_xyxy *= scale\n",
    "    keypoints[..., 0] *= orig_w / img_size\n",
    "    keypoints[..., 1] *= orig_h / img_size\n",
    "    results = []\n",
    "    for b, s, c, kp in zip(boxes_xyxy, scores, classes, keypoints):\n",
    "        results.append({\n",
    "            \"box\": b.int().tolist(),\n",
    "            \"score\": float(s),\n",
    "            \"class\": int(c),\n",
    "            \"keypoints\": kp.cpu().numpy()\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# --------------------------------------\n",
    "# 🔌 아두이노 통신\n",
    "# --------------------------------------\n",
    "def find_stm32_port():\n",
    "    ports = serial.tools.list_ports.comports()\n",
    "    for port in ports:\n",
    "        if (\"STM\" in port.description or \"STLink\" in port.description or \"ttyACM\" in port.device or \"ttyUSB\" in port.device):\n",
    "            return port.device\n",
    "    raise Exception(\"STM32 포트를 찾을 수 없습니다.\")\n",
    "\n",
    "def send_command():\n",
    "    port = find_stm32_port()\n",
    "    ser = serial.Serial(port, 9600)\n",
    "    time.sleep(2)\n",
    "    ser.write(b'1')\n",
    "    print(\"✅ 먹이 지급 신호 전송 완료\")\n",
    "    ser.close()\n",
    "\n",
    "# --------------------------------------\n",
    "# 🎯 훈련 루프 (5회 반복)\n",
    "# --------------------------------------\n",
    "cap = cv2.VideoCapture(1)\n",
    "class_labels = [\"default\", \"sitting\", \"lying\"]\n",
    "label_map = {\"앉아\": 1, \"엎드려\": 2}\n",
    "training_rounds = 5\n",
    "\n",
    "for round_num in range(training_rounds):\n",
    "    speak(\"동구야~ 이리와아~!!\")\n",
    "    speak(\"동구야~ 이리와아~!!\")\n",
    "\n",
    "    \n",
    "    command = random.choice([\"앉아\", \"엎드려\"])\n",
    "    if command == \"앉아\":\n",
    "        speak(\"착하지~~ 앉아~\")\n",
    "        speak(\"앉아~~\")\n",
    "    elif command == \"엎드려\":\n",
    "        speak(\"엎드려~~!\")\n",
    "        speak(\"엎드려~!!\")\n",
    "         \n",
    "  \n",
    "\n",
    "# 내부 로직은 그대로 유지\n",
    "    if command not in label_map:\n",
    "        print(\"❌ 잘못된 명령입니다.\")\n",
    "        continue\n",
    "    target_label_id = label_map[command]\n",
    "    start_time = None\n",
    "    success_sent = False\n",
    "    training_start_time = time.time()\n",
    "\n",
    "    while time.time() - training_start_time < 3600:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        orig_h, orig_w = frame.shape[:2]\n",
    "        input_tensor = preprocess_frame(frame)\n",
    "        with torch.no_grad():\n",
    "            preds = model(input_tensor)\n",
    "        detections = postprocess_yolo(preds, (orig_h, orig_w))\n",
    "        detected = any(det[\"class\"] == target_label_id for det in detections)\n",
    "        if detected:\n",
    "            if start_time is None:\n",
    "                start_time = time.time()\n",
    "            elif time.time() - start_time >= 3 and not success_sent:\n",
    "                speak(\"잘했어~ 아주 잘했어~!\")\n",
    "                send_command()\n",
    "                success_sent = True\n",
    "                break\n",
    "        else:\n",
    "            start_time = None\n",
    "        cv2.imshow(\"훈련 중\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        speak(\"시간 초과! 훈련 종료\")\n",
    "        print(\"⏰ 1시간 내에 행동 인식 실패 → 훈련 종료\")\n",
    "\n",
    "speak(\"훈련이 모두 끝났어요\")\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 목소리 조정\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📣 테스트용 TTS 음성 재생 중...\n",
      "\n",
      "▶️ 문장 1: 동구야 이리와~!\n",
      "\n",
      "▶️ 문장 2: 동구야~ 이리와아~!!\n",
      "\n",
      "▶️ 문장 3: 동구야~ 이리와아~!!착하지~ 앉아~\n",
      "\n",
      "▶️ 문장 4: 앉아~엎드려~!\n",
      "\n",
      "▶️ 문장 5: 엎드려!!우와~ 동구야 잘했어~!!\n",
      "✅ 모든 문장 재생 완료!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import pygame\n",
    "from elevenlabs import ElevenLabs\n",
    "\n",
    "# API 키와 설정\n",
    "ELEVENLABS_API_KEY = \"sk_ecf257b80f9b85371df2bacf86ca5cc519c5e28ddd679c76\"\n",
    "VOICE_ID = \"uyVNoMrnUku1dZyVEXwD\"\n",
    "\n",
    "# ElevenLabs 클라이언트 초기화\n",
    "client = ElevenLabs(api_key=ELEVENLABS_API_KEY)\n",
    "\n",
    "# 테스트할 문장 리스트\n",
    "test_sentences = [\n",
    "    \"동구야 이리와~!\",\n",
    "\n",
    "    \"동구야~ 이리와아~!!\",\n",
    "    \"동구야~ 이리와아~!!\" \n",
    "\n",
    "    \"착하지~ 앉아~\",\n",
    "    \"앉아~\"\n",
    "\n",
    "    \"엎드려~!\",\n",
    "    \"엎드려!!\"\n",
    "\n",
    "    \"우와~ 동구야 잘했어~!!\"\n",
    "]\n",
    "\n",
    "# 보이스 세팅 값 여러 조합 시도 가능\n",
    "voice_settings = {\n",
    "    \"stability\": 0.2,\n",
    "    \"similarity_boost\": 0.8,\n",
    "    \"style\": 0.9\n",
    "}\n",
    "\n",
    "# 재생 함수\n",
    "def play_voice(text):\n",
    "    audio_stream = client.text_to_speech.convert(\n",
    "        text=text,\n",
    "        voice_id=VOICE_ID,\n",
    "        model_id=\"eleven_multilingual_v2\",\n",
    "        voice_settings=voice_settings\n",
    "    )\n",
    "    audio_bytes = b\"\".join(chunk for chunk in audio_stream)\n",
    "\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\") as temp_audio:\n",
    "        temp_audio.write(audio_bytes)\n",
    "        audio_path = temp_audio.name\n",
    "\n",
    "    pygame.mixer.init()\n",
    "    pygame.mixer.music.load(audio_path)\n",
    "    pygame.mixer.music.play()\n",
    "    while pygame.mixer.music.get_busy():\n",
    "        pygame.time.Clock().tick(10)\n",
    "    pygame.mixer.quit()\n",
    "\n",
    "    os.remove(audio_path)\n",
    "\n",
    "# 실행\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"📣 테스트용 TTS 음성 재생 중...\")\n",
    "    for idx, sentence in enumerate(test_sentences):\n",
    "        print(f\"\\n▶️ 문장 {idx+1}: {sentence}\")\n",
    "        play_voice(sentence)\n",
    "    print(\"✅ 모든 문장 재생 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

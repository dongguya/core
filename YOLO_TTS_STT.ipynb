{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pygame\n",
      "  Downloading pygame-2.6.1-cp39-cp39-win_amd64.whl.metadata (13 kB)\n",
      "Downloading pygame-2.6.1-cp39-cp39-win_amd64.whl (10.6 MB)\n",
      "   ---------------------------------------- 0.0/10.6 MB ? eta -:--:--\n",
      "   ------------------------ --------------- 6.6/10.6 MB 31.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.6/10.6 MB 25.5 MB/s eta 0:00:00\n",
      "Installing collected packages: pygame\n",
      "Successfully installed pygame-2.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pygame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import torch\n",
    "import numpy as np\n",
    "import serial\n",
    "import serial.tools.list_ports\n",
    "import random\n",
    "from elevenlabs import ElevenLabs\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import tempfile\n",
    "import pygame\n",
    "\n",
    "# API Key ì§ì ‘ ì„¤ì •\n",
    "load_dotenv()\n",
    "ELEVENLABS_API_KEY = os.getenv(\"ELEVENLABS_API_KEY\")\n",
    "VOICE_ID = \"uyVNoMrnUku1dZyVEXwD\"\n",
    "\n",
    "# Init client\n",
    "client_tts = ElevenLabs(api_key=ELEVENLABS_API_KEY)\n",
    "\n",
    "# Device setting\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = torch.jit.load(\"dongguya.torchscript\", map_location=device)\n",
    "model.eval()\n",
    "\n",
    "# --------------------------------------\n",
    "# ğŸ”Š TTS: speak í•¨ìˆ˜ (ì‹¤ì‹œê°„ ì¬ìƒ, pygame ì‚¬ìš©)\n",
    "# --------------------------------------\n",
    "def speak(text):\n",
    "    audio_stream = client_tts.text_to_speech.convert(\n",
    "        text=text,\n",
    "        voice_id=VOICE_ID,\n",
    "        model_id=\"eleven_multilingual_v2\",\n",
    "        voice_settings={  \n",
    "        \"stability\": 0.2,\n",
    "        \"similarity_boost\": 0.8,\n",
    "        \"style\": 0.9\n",
    "        }\n",
    "\n",
    "    )\n",
    "    audio_bytes = b\"\".join(chunk for chunk in audio_stream)\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\") as temp_audio:\n",
    "        temp_audio.write(audio_bytes)\n",
    "        temp_audio_path = temp_audio.name\n",
    "\n",
    "    pygame.mixer.init()\n",
    "    pygame.mixer.music.load(temp_audio_path)\n",
    "    pygame.mixer.music.play()\n",
    "    while pygame.mixer.music.get_busy():\n",
    "        pygame.time.Clock().tick(10)\n",
    "    pygame.mixer.quit()\n",
    "\n",
    "    os.remove(temp_audio_path)\n",
    "\n",
    "# --------------------------------------\n",
    "# ğŸ“¦ YOLO ê´€ë ¨ ì „ì²˜ë¦¬ & í›„ì²˜ë¦¬ í•¨ìˆ˜\n",
    "# --------------------------------------\n",
    "def preprocess_frame(frame, img_size=640):\n",
    "    img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    img = cv2.resize(img, (img_size, img_size))\n",
    "    img = img.astype(np.float32) / 255.0\n",
    "    tensor = torch.from_numpy(img).permute(2, 0, 1).unsqueeze(0)\n",
    "    return tensor.to(device)\n",
    "\n",
    "def box_iou(box1, box2):\n",
    "    x1 = torch.max(box1[:, None, 0], box2[:, 0])\n",
    "    y1 = torch.max(box1[:, None, 1], box2[:, 1])\n",
    "    x2 = torch.min(box1[:, None, 2], box2[:, 2])\n",
    "    y2 = torch.min(box1[:, None, 3], box2[:, 3])\n",
    "    inter = (x2 - x1).clamp(0) * (y2 - y1).clamp(0)\n",
    "    area1 = (box1[:, 2] - box1[:, 0]) * (box1[:, 3] - box1[:, 1])\n",
    "    area2 = (box2[:, 2] - box2[:, 0]) * (box2[:, 3] - box2[:, 1])\n",
    "    union = area1[:, None] + area2 - inter\n",
    "    return inter / union\n",
    "\n",
    "def simple_nms(boxes, scores, iou_threshold=0.5):\n",
    "    idxs = scores.argsort(descending=True)\n",
    "    keep = []\n",
    "    while idxs.numel() > 0:\n",
    "        current = idxs[0].item()\n",
    "        keep.append(current)\n",
    "        if idxs.numel() == 1:\n",
    "            break\n",
    "        ious = box_iou(boxes[current].unsqueeze(0), boxes[idxs[1:]])[0]\n",
    "        idxs = idxs[1:][ious < iou_threshold]\n",
    "    return keep\n",
    "\n",
    "def postprocess_yolo(preds, orig_shape, conf_threshold=0.5, iou_threshold=0.5, img_size=640):\n",
    "    preds = preds.permute(0, 2, 1)[0]\n",
    "    cls_confidences = preds[:, 4:7]\n",
    "    cls_conf, cls_ids = cls_confidences.max(dim=1)\n",
    "    mask = cls_conf > conf_threshold\n",
    "    if not mask.any():\n",
    "        return []\n",
    "    boxes = preds[mask, :4]\n",
    "    scores = cls_conf[mask]\n",
    "    classes = cls_ids[mask]\n",
    "    keypoints = preds[mask, 7:].reshape(-1, 24, 3)\n",
    "    xy = boxes[:, :2] - boxes[:, 2:] / 2\n",
    "    wh = boxes[:, :2] + boxes[:, 2:]\n",
    "    boxes_xyxy = torch.cat((xy, wh), dim=1)\n",
    "    keep = simple_nms(boxes_xyxy, scores, iou_threshold)\n",
    "    boxes_xyxy = boxes_xyxy[keep]\n",
    "    scores = scores[keep]\n",
    "    classes = classes[keep]\n",
    "    keypoints = keypoints[keep]\n",
    "    orig_h, orig_w = orig_shape\n",
    "    scale = torch.tensor([orig_w / img_size, orig_h / img_size, orig_w / img_size, orig_h / img_size], device=boxes_xyxy.device)\n",
    "    boxes_xyxy *= scale\n",
    "    keypoints[..., 0] *= orig_w / img_size\n",
    "    keypoints[..., 1] *= orig_h / img_size\n",
    "    results = []\n",
    "    for b, s, c, kp in zip(boxes_xyxy, scores, classes, keypoints):\n",
    "        results.append({\n",
    "            \"box\": b.int().tolist(),\n",
    "            \"score\": float(s),\n",
    "            \"class\": int(c),\n",
    "            \"keypoints\": kp.cpu().numpy()\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# --------------------------------------\n",
    "# ğŸ”Œ ì•„ë‘ì´ë…¸ í†µì‹ \n",
    "# --------------------------------------\n",
    "def find_stm32_port():\n",
    "    ports = serial.tools.list_ports.comports()\n",
    "    for port in ports:\n",
    "        if (\"STM\" in port.description or \"STLink\" in port.description or \"ttyACM\" in port.device or \"ttyUSB\" in port.device):\n",
    "            return port.device\n",
    "    raise Exception(\"STM32 í¬íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "def send_command():\n",
    "    port = find_stm32_port()\n",
    "    ser = serial.Serial(port, 9600)\n",
    "    time.sleep(2)\n",
    "    ser.write(b'1')\n",
    "    print(\"âœ… ë¨¹ì´ ì§€ê¸‰ ì‹ í˜¸ ì „ì†¡ ì™„ë£Œ\")\n",
    "    ser.close()\n",
    "\n",
    "# --------------------------------------\n",
    "# ğŸ¯ í›ˆë ¨ ë£¨í”„ (5íšŒ ë°˜ë³µ)\n",
    "# --------------------------------------\n",
    "cap = cv2.VideoCapture(1)\n",
    "class_labels = [\"default\", \"sitting\", \"lying\"]\n",
    "label_map = {\"ì•‰ì•„\": 1, \"ì—ë“œë ¤\": 2}\n",
    "training_rounds = 5\n",
    "\n",
    "for round_num in range(training_rounds):\n",
    "    speak(\"ë™êµ¬ì•¼~ ì´ë¦¬ì™€ì•„~!!\")\n",
    "    speak(\"ë™êµ¬ì•¼~ ì´ë¦¬ì™€ì•„~!!\")\n",
    "\n",
    "    \n",
    "    command = random.choice([\"ì•‰ì•„\", \"ì—ë“œë ¤\"])\n",
    "    if command == \"ì•‰ì•„\":\n",
    "        speak(\"ì°©í•˜ì§€~~ ì•‰ì•„~\")\n",
    "        speak(\"ì•‰ì•„~~\")\n",
    "    elif command == \"ì—ë“œë ¤\":\n",
    "        speak(\"ì—ë“œë ¤~~!\")\n",
    "        speak(\"ì—ë“œë ¤~!!\")\n",
    "         \n",
    "  \n",
    "\n",
    "# ë‚´ë¶€ ë¡œì§ì€ ê·¸ëŒ€ë¡œ ìœ ì§€\n",
    "    if command not in label_map:\n",
    "        print(\"âŒ ì˜ëª»ëœ ëª…ë ¹ì…ë‹ˆë‹¤.\")\n",
    "        continue\n",
    "    target_label_id = label_map[command]\n",
    "    start_time = None\n",
    "    success_sent = False\n",
    "    training_start_time = time.time()\n",
    "\n",
    "    while time.time() - training_start_time < 3600:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        orig_h, orig_w = frame.shape[:2]\n",
    "        input_tensor = preprocess_frame(frame)\n",
    "        with torch.no_grad():\n",
    "            preds = model(input_tensor)\n",
    "        detections = postprocess_yolo(preds, (orig_h, orig_w))\n",
    "        detected = any(det[\"class\"] == target_label_id for det in detections)\n",
    "        if detected:\n",
    "            if start_time is None:\n",
    "                start_time = time.time()\n",
    "            elif time.time() - start_time >= 3 and not success_sent:\n",
    "                speak(\"ì˜í–ˆì–´~ ì•„ì£¼ ì˜í–ˆì–´~!\")\n",
    "                send_command()\n",
    "                success_sent = True\n",
    "                break\n",
    "        else:\n",
    "            start_time = None\n",
    "        cv2.imshow(\"í›ˆë ¨ ì¤‘\", frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        speak(\"ì‹œê°„ ì´ˆê³¼! í›ˆë ¨ ì¢…ë£Œ\")\n",
    "        print(\"â° 1ì‹œê°„ ë‚´ì— í–‰ë™ ì¸ì‹ ì‹¤íŒ¨ â†’ í›ˆë ¨ ì¢…ë£Œ\")\n",
    "\n",
    "speak(\"í›ˆë ¨ì´ ëª¨ë‘ ëë‚¬ì–´ìš”\")\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ëª©ì†Œë¦¬ ì¡°ì •\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“£ í…ŒìŠ¤íŠ¸ìš© TTS ìŒì„± ì¬ìƒ ì¤‘...\n",
      "\n",
      "â–¶ï¸ ë¬¸ì¥ 1: ë™êµ¬ì•¼ ì´ë¦¬ì™€~!\n",
      "\n",
      "â–¶ï¸ ë¬¸ì¥ 2: ë™êµ¬ì•¼~ ì´ë¦¬ì™€ì•„~!!\n",
      "\n",
      "â–¶ï¸ ë¬¸ì¥ 3: ë™êµ¬ì•¼~ ì´ë¦¬ì™€ì•„~!!ì°©í•˜ì§€~ ì•‰ì•„~\n",
      "\n",
      "â–¶ï¸ ë¬¸ì¥ 4: ì•‰ì•„~ì—ë“œë ¤~!\n",
      "\n",
      "â–¶ï¸ ë¬¸ì¥ 5: ì—ë“œë ¤!!ìš°ì™€~ ë™êµ¬ì•¼ ì˜í–ˆì–´~!!\n",
      "âœ… ëª¨ë“  ë¬¸ì¥ ì¬ìƒ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import pygame\n",
    "from elevenlabs import ElevenLabs\n",
    "\n",
    "# API í‚¤ì™€ ì„¤ì •\n",
    "ELEVENLABS_API_KEY = \"sk_ecf257b80f9b85371df2bacf86ca5cc519c5e28ddd679c76\"\n",
    "VOICE_ID = \"uyVNoMrnUku1dZyVEXwD\"\n",
    "\n",
    "# ElevenLabs í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”\n",
    "client = ElevenLabs(api_key=ELEVENLABS_API_KEY)\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸í•  ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸\n",
    "test_sentences = [\n",
    "    \"ë™êµ¬ì•¼ ì´ë¦¬ì™€~!\",\n",
    "\n",
    "    \"ë™êµ¬ì•¼~ ì´ë¦¬ì™€ì•„~!!\",\n",
    "    \"ë™êµ¬ì•¼~ ì´ë¦¬ì™€ì•„~!!\" \n",
    "\n",
    "    \"ì°©í•˜ì§€~ ì•‰ì•„~\",\n",
    "    \"ì•‰ì•„~\"\n",
    "\n",
    "    \"ì—ë“œë ¤~!\",\n",
    "    \"ì—ë“œë ¤!!\"\n",
    "\n",
    "    \"ìš°ì™€~ ë™êµ¬ì•¼ ì˜í–ˆì–´~!!\"\n",
    "]\n",
    "\n",
    "# ë³´ì´ìŠ¤ ì„¸íŒ… ê°’ ì—¬ëŸ¬ ì¡°í•© ì‹œë„ ê°€ëŠ¥\n",
    "voice_settings = {\n",
    "    \"stability\": 0.2,\n",
    "    \"similarity_boost\": 0.8,\n",
    "    \"style\": 0.9\n",
    "}\n",
    "\n",
    "# ì¬ìƒ í•¨ìˆ˜\n",
    "def play_voice(text):\n",
    "    audio_stream = client.text_to_speech.convert(\n",
    "        text=text,\n",
    "        voice_id=VOICE_ID,\n",
    "        model_id=\"eleven_multilingual_v2\",\n",
    "        voice_settings=voice_settings\n",
    "    )\n",
    "    audio_bytes = b\"\".join(chunk for chunk in audio_stream)\n",
    "\n",
    "    with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\") as temp_audio:\n",
    "        temp_audio.write(audio_bytes)\n",
    "        audio_path = temp_audio.name\n",
    "\n",
    "    pygame.mixer.init()\n",
    "    pygame.mixer.music.load(audio_path)\n",
    "    pygame.mixer.music.play()\n",
    "    while pygame.mixer.music.get_busy():\n",
    "        pygame.time.Clock().tick(10)\n",
    "    pygame.mixer.quit()\n",
    "\n",
    "    os.remove(audio_path)\n",
    "\n",
    "# ì‹¤í–‰\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"ğŸ“£ í…ŒìŠ¤íŠ¸ìš© TTS ìŒì„± ì¬ìƒ ì¤‘...\")\n",
    "    for idx, sentence in enumerate(test_sentences):\n",
    "        print(f\"\\nâ–¶ï¸ ë¬¸ì¥ {idx+1}: {sentence}\")\n",
    "        play_voice(sentence)\n",
    "    print(\"âœ… ëª¨ë“  ë¬¸ì¥ ì¬ìƒ ì™„ë£Œ!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
